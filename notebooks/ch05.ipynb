{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0105abc-6923-484e-bb0b-a4e3542df58e",
   "metadata": {},
   "source": [
    "# Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b7b5a-e770-454b-9487-0b2a9b8a7ddd",
   "metadata": {},
   "source": [
    "Pandas has multiple possible underlying type systems. There are the classic NumPy types, but also the new PyArrow types. These can coexist in the same data frame, but seemingly similar types can have different properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665b2ff4-1ec5-4184-b543-3d4f2bc557f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([1.0, 2.0, 3.0], dtype=\"float64\")\n",
    "s2 = pd.Series([0.3, 1.3, 2.7], dtype=\"float64[pyarrow]\")\n",
    "\n",
    "df = pd.DataFrame({\"first\": s1, \"second\": s2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e0507b-fdfe-4ae1-95b7-28e56d7671a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype          \n",
      "---  ------  --------------  -----          \n",
      " 0   first   3 non-null      float64        \n",
      " 1   second  3 non-null      double[pyarrow]\n",
      "dtypes: double[pyarrow](1), float64(1)\n",
      "memory usage: 180.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd5d38-bb94-4520-b457-6dfa3f1bac3e",
   "metadata": {},
   "source": [
    "Properties of NumPy types:\n",
    "- Automatic type conversion to Python `int` when dealing with large integers\n",
    "- Automatic type conversion to `float64` when `NaN` values appear\n",
    "- Conversion to \"smaller\" types is possible; overflows will happen without warning\n",
    "- NumPy doesn't have a string type; strings are treated as general `object`s\n",
    "\n",
    "Properties of PyArrow types:\n",
    "- No automatic type conversions for large integers; an error is thrown instead\n",
    "- No automatic overflows will happen when converting to smaller types; an error is thrown if one would occur\n",
    "- Integer types can handle `<NA>` values\n",
    "- No direct conversion from strings to floating point types; you must go through NumPy\n",
    "- PyArrow does have a dedicated string type, but you need to create it with `pd.ArrowDtype(pa.String())`\n",
    "    - The situation has changed since the book was published, but it's still unclear what the best approach to using strings is\n",
    "    - This will be clarified in Pandas 3.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff531f9-0a15-444e-852b-3c0ea5002201",
   "metadata": {},
   "source": [
    "## Integer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88352980-f7ea-4b1e-b6f6-c911af49b601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1     99\n",
       "2    127\n",
       "dtype: int8[pyarrow]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_values = [1, 99, 127]\n",
    "small_ser = pd.Series(small_values, dtype=\"int8[pyarrow]\")\n",
    "small_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7137cd5b-87a0-4096-ae23-221abf6c358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         2147483648\n",
       "1                9223372036854775808\n",
       "2    1267650600228229401496703205376\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_values = [2**31, 2**63, 2**100]\n",
    "large_ser = pd.Series(large_values) # hard to do with PyArrow types\n",
    "large_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff8662-fe59-4034-a85d-2b65dfec2187",
   "metadata": {},
   "source": [
    "It's possible to have missing values in integer arrays with PyArrow types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3d676e-1d04-476f-88cf-031d99987546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <NA>\n",
       "1       1\n",
       "2     -45\n",
       "dtype: int8[pyarrow]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = [None, 1, -45]\n",
    "missing_ser = pd.Series(missing_values, dtype=\"int8[pyarrow]\")\n",
    "missing_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e15c1d-0b37-4ebc-b286-a15b927ac5e9",
   "metadata": {},
   "source": [
    "## Floating Point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a929d13-0fbc-4537-97c0-ce2d3f4f7337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.5\n",
       "1      3.7\n",
       "2    127.0\n",
       "dtype: double[pyarrow]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_vals = [1.5, 3.7, 127.0]\n",
    "pd.Series(float_vals, dtype=\"float64[pyarrow]\") # or double[pyarrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41c7266-3899-4e72-a4a4-5b05fd6fe283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <NA>\n",
       "1     1.5\n",
       "2   -45.0\n",
       "dtype: double[pyarrow]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_missing = [None, 1.5, -45.0]\n",
    "pd.Series(float_missing, dtype=\"float64[pyarrow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15596383-1b5e-4abd-9fdf-ad335d567a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.5\n",
       "1    2.7\n",
       "2    0.0\n",
       "3      T\n",
       "4    1.5\n",
       "5      0\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_rain = [1.5, 2.7, 0.0, \"T\", 1.5, 0]\n",
    "pd.Series(float_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1168409-dfcf-4833-b70c-bbcb5601353e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.5\n",
       "1    2.7\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.5\n",
       "5      0\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(float_rain).replace(\"T\", \"0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d3223-fe5d-46b7-8100-a8773477526e",
   "metadata": {},
   "source": [
    "The series above looks fine, but the `0.0` at index 3 is actually a string, so converting it to `float64[pyarrow]` won't work.\n",
    "\n",
    "We need to convert the `\"T\"` into a numeric `0.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ea7786-4e3f-46ac-a5af-c7308c39834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18448/1529167157.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pd.Series(float_rain).replace(\"T\", 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.5\n",
       "1    2.7\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.5\n",
       "5    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(float_rain).replace(\"T\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55de995d-fb06-40bf-bb8b-0a65aadb3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18448/771965346.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pd.Series(float_rain).replace(\"T\", 0.0).astype(\"float64[pyarrow]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.5\n",
       "1    2.7\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.5\n",
       "5    0.0\n",
       "dtype: double[pyarrow]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(float_rain).replace(\"T\", 0.0).astype(\"float64[pyarrow]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55558b-363b-40c7-b54a-8c15849d160f",
   "metadata": {},
   "source": [
    "## String data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6105542e-820d-4e6a-b01e-8bb697a963bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "string_pa = pd.ArrowDtype(pa.string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763f7ef2-3899-4b11-874c-4f6b4078e277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       My name is Jeff\n",
       "1         I like pandas\n",
       "2    I like programming\n",
       "dtype: string[pyarrow]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_freeform = [\"My name is Jeff\", \"I like pandas\", \"I like programming\"]\n",
    "pd.Series(text_freeform, dtype=string_pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c90725-2294-4c73-a363-3a8e39bc69fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       My name is Jeff\n",
       "1                  <NA>\n",
       "2    I like programming\n",
       "dtype: string[pyarrow]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_with_missing = [\"My name is Jeff\", None, \"I like programming\"]\n",
    "pd.Series(text_with_missing, dtype=string_pa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a733efc-f5a6-43c1-bc6f-d7e63f004da0",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fe21f-6ccc-48c1-a42b-6586920e206a",
   "metadata": {},
   "source": [
    "Use the `category` type for categorical data with a *low* number of categories. If there are too many categories, this becomes less efficient than treating the values as strings. PyArrow has a `dictionary` type for this kind of data, but the author ignores it in favor of the Pandas 1.x `category` type. `dictionary` is not exposed directly in Pandas unlike other PyArrow data types.\n",
    "\n",
    "Pandas also supports ordered categories in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e48e0a-f7b0-48e7-8bf0-2f87b91c4828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    CA\n",
       "1    NY\n",
       "2    TX\n",
       "dtype: category\n",
       "Categories (3, object): ['CA', 'NY', 'TX']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = ['CA', 'NY', 'TX']\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "pd.Series(states, dtype='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd7bfd1-0151-4e8a-98ec-6dde903d52bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan\n",
       "1     Feb\n",
       "2     Mar\n",
       "3     Apr\n",
       "4     May\n",
       "5     Jun\n",
       "6     Jul\n",
       "7     Aug\n",
       "8     Sep\n",
       "9     Oct\n",
       "10    Nov\n",
       "11    Dec\n",
       "dtype: category\n",
       "Categories (12, object): ['Jan' < 'Feb' < 'Mar' < 'Apr' ... 'Sep' < 'Oct' < 'Nov' < 'Dec']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_cat = pd.CategoricalDtype(categories=months, ordered=True)\n",
    "pd.Series(months, dtype=month_cat).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0dabf55-bea6-4cf9-a3c8-a3004eb8ace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan\n",
       "1     Feb\n",
       "2     Mar\n",
       "3     Apr\n",
       "4     May\n",
       "5     Jun\n",
       "6     Jul\n",
       "7     Aug\n",
       "8     Sep\n",
       "9     Oct\n",
       "10    Nov\n",
       "11    Dec\n",
       "dtype: category\n",
       "Categories (12, object): ['Jan' < 'Feb' < 'Mar' < 'Apr' ... 'Sep' < 'Oct' < 'Nov' < 'Dec']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(months, dtype=string_pa).astype(month_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca35f164-2a8f-44d7-9c8d-8a7b0da7f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan\n",
       "1     Feb\n",
       "2     Mar\n",
       "3     Apr\n",
       "4     May\n",
       "5     Jun\n",
       "6     Jul\n",
       "7     Aug\n",
       "8     Sep\n",
       "9     Oct\n",
       "10    Nov\n",
       "11    Dec\n",
       "dtype: category\n",
       "Categories (12, string[pyarrow]): [Jan < Feb < Mar < Apr ... Sep < Oct < Nov < Dec]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not included in book, but this is how to use the 1.x categorical type with an\n",
    "# underlying 2.x PyArrow data type.\n",
    "month_cat = pd.CategoricalDtype(categories=pd.Series(months, dtype=string_pa), ordered=True)\n",
    "pd.Series(months, dtype=string_pa).astype(month_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db2768-fd9c-4609-808b-e9453fe31e09",
   "metadata": {},
   "source": [
    "## Dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4405f577-234c-4533-a5ff-c0826acf3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "dt_list = [dt.datetime(2020, 1, 1, 4, 30), dt.datetime(2020, 1, 2), dt.datetime(2020, 1, 3)]\n",
    "string_dates = ['2020-01-01 04:30:00', '2020-01-02 00:00:00', '2020-01-03 00:00:00']\n",
    "string_dates_missing = ['2020-01-01 4:30', None, '2020-01-03']\n",
    "epoch_dates = [1577836800, 1577923200, 1578009600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "765e987d-6bc0-45a0-a9dc-43eef1898961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01 04:30:00\n",
       "1   2020-01-02 00:00:00\n",
       "2   2020-01-03 00:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2809287-cd09-4ca4-8d12-a596e0c0e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01 04:30:00\n",
       "1   2020-01-02 00:00:00\n",
       "2   2020-01-03 00:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string_dates, dtype='datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77db0fa5-724d-4297-b395-fa4c81fc7411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01 04:30:00\n",
       "1                   NaT\n",
       "2   2020-01-03 00:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string_dates_missing, dtype='datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b06b5-1887-4276-9fab-dda2678d0168",
   "metadata": {},
   "source": [
    "Be careful with epoch times; make sure you know the units. Here, the times are in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45365102-521d-4517-8b45-a61a5bcb3553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01\n",
       "1   2020-01-02\n",
       "2   2020-01-03\n",
       "dtype: datetime64[s]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(epoch_dates, dtype='datetime64[s]') # contrast with dtype='datetime64[ns]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b9ff589-cf4d-44df-b8a2-0c127e67edfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 04:30:00\n",
       "1    2020-01-02 00:00:00\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[ns][pyarrow]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dt_list, dtype='timestamp[ns][pyarrow]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05656a5-fe94-4a3b-a699-a3b47a9ffa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 04:30:00\n",
       "1    2020-01-02 00:00:00\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[ns][pyarrow]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string_dates, dtype='timestamp[ns][pyarrow]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ccf1f-241a-4ca5-b7f9-4799b7da92d2",
   "metadata": {},
   "source": [
    "PyArrow timestamp conversions require all timestamps to have a common format:\n",
    "\n",
    "`pd.Series(string_dates_missing, dtype='timestamp[ns][pyarrow]')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1862e595-6253-4732-9379-ab322860d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 04:30:00\n",
       "1                   <NA>\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[ns][pyarrow]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_dates_missing_2 = ['2020-01-01 4:30', None, '2020-01-03 0:00']\n",
    "pd.Series(string_dates_missing_2, dtype=\"timestamp[ns][pyarrow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68e65c62-ef46-4986-ae16-61d933888ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 00:00:00\n",
       "1    2020-01-02 00:00:00\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[s][pyarrow]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(epoch_dates, dtype='timestamp[s][pyarrow]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669414b-fab6-437c-bbaa-9d35cf86078b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16a449-cb92-48f7-8279-347e1bb69512",
   "metadata": {},
   "source": [
    "1. To represent the number of people in the US, I would use the `uint32[pyarrow]` type, which has a maximum value of around 4 billion. For the number of people worldwide, I would use the `uint64[pyarrow]` type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec70196-6d81-4395-a886-111e43e93b33",
   "metadata": {},
   "source": [
    "2. To describe a product, I would likely use the `category` type. For the name, I would use a PyArrow string. For the price, I might use a floating-point value like `float32[pyarrow]`, but PyArrow provides exact decimals with `decimal128(...)[pyarrow]`, so I might consider that for its precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a25f0-808d-4c4b-909b-142f6d519e6f",
   "metadata": {},
   "source": [
    "3. For the date and time of a stock trade, I would use the `timestamp[ns][pyarrow]` type. For a date of birth of a person, I would likely use the `date32[pyarrow]` type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
